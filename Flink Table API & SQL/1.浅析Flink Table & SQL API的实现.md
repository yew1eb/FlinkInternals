## Why Table & SQL API ?

unified APIs for batch and stream processing
### 实际上DataStream API已经非常棒了
1. 拥有非常强的流计算表达能力
Transform data, update state, define windows, aggregate, exantly once, etc.
2. 非常灵活的自定义window逻辑
Assigners, Trggers, Evictors, Lateness
3. Asynchronous I/O
提升了访问外部系统的性能
4. low-level operations
ProcessFunction gives access to timestamps and timers
### 但是并非是对所有人如此！
1. 写一个DataStream的程序并不简单
    流计算技术发展变化的速度太快了
    新的流处理概念（time, state, windows,...)
2. 需要一些必要的知识和技能
    这种常驻应用需要一些特殊的配置，比如内存，垃圾回收，如何配置watermarks
    ,ProcessFunction
    编程的经验（java/Scala/maven)
3. 用户仅仅是想专注于他们的业务逻辑,对于有一些做算法的同学可能他们并不擅长于java和Scala

## Why not a Relational API ?
1. 关系型API是声明式的
用户说什么，系统就知道怎么去计算它
2. 查询能够被有效的优化
   很少有黑盒，良好的研究领域，查询优化
3. 查询可以有效的被执行
    让Flink控制state, time, and common mistakes
4. "Everybody" knows and uses SQL!

## Goals
1. 容易的，声明式，简单的关系型API
2. 为绝大多数应用场景提供工具化
3. 关系型API是一个统一的抽象层
    查询一个批处理表可以产生一个有限的结果
    查询一个流表持续的运行，产生结果流
4. 相同的语法和语义对于这两种查询

## Table API & SQL
Flink提供两种关系型的APIs
​    Table API: LinQ-style for Java & Scala(since Flink 0.9.0)
​    SQL: Standard SQL(since Flink 1.1.0)

### table APi & SQL example

```
val tEnv = TableEnvironment.getTableEnvironment(env)
//配置数据源
val customerSource = CsvTableSource.builder()
  .path("/path/to/customer_data.csv")
  .field("name", Types.STRING).field("prefs", Types.STRING)
  .build()
//将数据源注册为一个Table
tEnv.registerTableSource(”cust", customerSource)
//定义你的table程序（在一个Flink程序中Table API和SQL API可以混用）
val table = tEnv.scan("cust").select('name.lowerCase(), myParser('prefs))
val table = tEnv.sql("SELECT LOWER(name), myParser(prefs) FROM cust")
//转换为DataStraem
val ds: DataStream[Customer] = table.toDataStream[Customer]
```
#### Windowing in Table API

```java
val sensorData: DataStream[(String, Long, Double)] = ???
// convert DataSet into Table
val sensorTable: Table = sensorData
  .toTable(tableEnv, 'location, 'time, 'tempF)
// define query on Table
val avgTempCTable: Table = sensorTable 
  .window(Tumble over 1.day on 'rowtime as 'w) 
  .groupBy('location, 'w)
  .select('w.start as 'day, 'location, (('tempF.avg - 32) * 0.556) as 'avgTempC)
  .where('location like "room%")
```

#### 展示了如何用 SQL 来实现。

```
val sensorData: DataStream[(String, Long, Double)] = ???
// register DataStream
tableEnv.registerDataStream("sensorData", sensorData, 'location, ’time, 'tempF)
// query registered Table
val avgTempCTable: Table = tableEnv.sql("""
  SELECT FLOOR(rowtime() TO DAY) AS day, location, 
    AVG((tempF - 32) * 0.556) AS  avgTempC
  FROM sensorData
  WHERE location LIKE 'room%'
  GROUP BY location, FLOOR(rowtime() TO DAY) """)
```

关系型API架构在基础的DataStream、DataSet API之上，其整体层次关系如下图所示：
![](img/table-sql-arch.png)

它们提供等价的特性集合，并且可以在同一个程序中混合使用，两者都与Flink的core API紧密集成。从上图来看，上层有两种API，而其下有两个基础（DataSet、DataStream）API作为后端。那这是否意味着实现时的四种组合的转换路径呢？
其实，Flink并没有自己去实现转换、SQL的解析、执行计划的生成、优化等操作，它将一些“不擅长”的任务转交给了Apache Calcite。整体架构如下图：

![](https://upload-images.jianshu.io/upload_images/5156328-e5d8b7f5d94d4115?imageMogr2/auto-orient/strip%7CimageView2/2/w/647)
新的架构中，构建抽象语法树的事情全部交给了 Calcite 去做。
+ SQL query 会经过默认的 Calcite Sql Parser转变成 SQL Node tree，通过validator验证（根据schema,type,built-in）之后仍然是Sql Node Tree, 之后通过Calcite SqlToRelConverter 将SqlNode转换成RelNode关系代数表达式（也就是图中的 Logical Plan）。
+ Table API 上的调用会构建成 Table API 的抽象语法树，并通过 Calcite 提供的 RelBuilder 转变成 Calcite 的抽象语法树。


我们来对上面的架构图进行解读。从中上部我们看到，可以从DataSet、DataStream以及Table Source等多种渠道来创建Table，
Table相关的一些信息比如schema、数据字段及类型等信息统一被注册并存放到Calcite Catalog中。这些信息将为Table & SQL API提供元数据。接着往下看，Table API跟SQL构建的查询将被翻译成共同的逻辑计划表示，逻辑计划将作为Calcite优化器的输入。优化器结合逻辑计划以及特定的后端（DataSet、DataStream）规则进行翻译和优化，随之产生不同的计划。计划将通过代码生成器，生成特定的后端程序。后端程序的执行将返回DataSet或DataStream。

这个架构图展示了Flink关系型API的整体架构，也是后续我们分析这个模块的基础。


以上面的温度计代码为样例，Table API 和 SQL 的转换流程如下，
绿色的节点代表 Flink Table Nodes，蓝色的节点代表 Calcite Logical Nodes。
最终都转化成了相同的 Logical Plan 表现形式。
![](img/flink-sql-example-calcite-tf.png)
**Table API** 调用Table API 实际上是创建了很多 Table API 的 LogicalNode，创建的过程中对会对整个query进行validate。
比如table是CalalogNode，window groupBy之后在select时会创建WindowAggregate和Project，where对应Filter。
然后用calcite.RelBuilder翻译成Calcite LogicalPlan。

**SQL** 如果是SQL API 将直接用Calcite的Parser进行解释然后validate生成Calcite LogicalPlan。

![](img/flink-sql-opt-tf-cg.png)
(1)之后会进入优化器，利用Calcite内置的一些rule来优化LogicalPlan，也可以自己添加或者覆盖这些rule。转换成Optimized Calcite Plan后，仍然是Calcite的内部表示方式。

优化规则说明：（Flink提供了批的优化规则，和流的优化规则）这里的优化规则分为两类，

一类是Calcite提供的内置优化规则（如条件下推，剪枝等），
再基于flink定制的一些优化rules(根据是streaming还是batch选择rulue)去优化logical Plan。
这两类规则的应用体现为下图中的①和②步骤，这两步骤都属于 Calcite 的优化阶段。

生成phsyical plan，基于flink里头的rules生成了DataStream Plan(Physical Plan)
将物Physical Plan转成Flink ExecutionPlan.

得到的DataStream Plan封装了如何将节transform成对应 DataStream/DataSet 程序的逻辑。

步骤③就是将不同的DataStream/DataSet Node通过代码生成（CodeGen），翻译成最终可执行的 DataStream/DataSet 程序。


 其通过调用相应的tanslateToPlan()转换和利用CodeGen成Flink的各种算子。

(org.apache.flink.table.codegen.Compiler)

CodeGen 出的Function以字符串的形式存在。在提交任务后会分发到各个 > TaskManager 中运行，在运行时会使用 [Janino](http://janino-> compiler.github.io/janino/) 编译器编译代码后运行。代码生成是 Table API & SQL 中最核心的一块内容。表达式、条件、内置函数等等是需要CodeGen出具体的Function 代码的，这部分跟Spark SQL的结构很相似。



## Streaming SQL 使用场景
![](img/use-cases-for-streaming-sql.png)
持续的ETL和数据导入
获取流式数据，然后转换这些数据（归一化，聚合…），将其写入其他系统（File，Kafka，DBMS）。这些query的结果通常会存储到log-style的系统。

实时的Dashboards 和 报表
获取流式数据，然后对数据进行聚合来支持在线系统（dashboard，推荐）或者数据分析系统（Tableau）。通常结果被写到k-v存储中（Cassandra，Hbase，可查询的Flink状态），建立索引（Elasticsearch）或者DBMS（MySQL，PostgreSQL…）。这些查询通常可以被更新，改进。

即席分析


针对流数据的即席查询，以实时的方式进行分析和浏览数据。查询结果直接显示在notebook（Apache Zeppelin）中。

Flink社区还提出来和数据库中Materialized View很相似的Dynamic table 动态表概念，将在以后的版本中支持，具体细节将另开文章解释。



## Table API & SQL 未来
Dynamic Tables

Dynamic Table 就是传统意义上的表，只不过表中的数据是会变化更新的。Flink 提出 Stream <–> Dynamic Table 之间是可以等价转换的。
不过这需要引入Retraction机制。有机会的话，我会专门写一篇文章来介绍。

Joins

包括了支持流与流的 Join，以及流与表的 Join。

SQL 客户端

目前 SQL 是需要内嵌到 Java/Scala 代码中运行的，不是纯 SQL 的使用方式。
未来需要支持 SQL 客户端执行提交 SQL 纯文本运行任务。

并行度设置

目前 Table API & SQL 是无法设置并行度的，这使得 Table API 看起来仍像个玩具。

在我看来，Flink 的 Table & SQL API 是走在时代前沿的，在很多方面在做着定义业界标准的事情，比如 SQL 上Window的表达，时间语义的表达，流和批语义的统一等。
在我看来，SQL 拥有更天然的流与批统一的特性，并且能够自动帮用户做很多SQL优化（下推、剪枝等），这是 Beam 所做不到的地方。
当然，未来如果 Table & SQL API 发展成熟的话，剥离出来作为业界标准的流与批统一的API也不是不可能（叫BeamTable，BeamSQL ？），哈哈。
这也是我非常看好 Table & SQL API，认为其大有潜力的一个原因。当然就目前来说，需要走的路还很长，Table API 现在还只是个玩具。

## 参考文献
+ [Flink Forward San Francisco 2018: Fabian Hueske & Timo Walther - "Why and how to leverage the simplicity and power of SQL on Flink"](https://www.slideshare.net/FlinkForward/flink-forward-san-francisco-2018-fabian-hueske-timo-walther-why-and-how-to-leverage-the-simplicity-and-power-of-sql-on-flink)
+ [Stream Processing for Everyone with SQL and Apache Flink - 2016](https://flink.apache.org/news/2016/05/24/stream-sql.html)
+ [From Streams to Tables and Back Again: An Update on Flink's Table & SQL API - 2017](https://flink.apache.org/news/2017/03/29/table-sql-api-update.html)
+ [Continuous Queries on Dynamic Tables - 2017](http://flink.apache.org/news/2017/04/04/dynamic-tables.html)
+ [锐眼洞察 | flink关系型API：Table API与SQL](http://blog.talkingdata.net/?p=4714)
+ [TiDB源码阅读系列文章] TiDB SQL Parser的实现

